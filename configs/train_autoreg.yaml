# Training configuration for autoregressive IntentTracker model
# This config references dataset_config.yaml for dataset and derived model parameters

# Dataset configuration
dataset_config: "dataset_config.yaml"  # Path to shared dataset config (relative to this file)

# Model configuration
model:
  model_type: 'autoreg'          # 'direct' for IntentTracker, 'diffusion' for DiffusionIntentTracker, 'autoreg' for AutoregressiveIntentTracker
  model_size: 's'                # 's' (small), 'b' (base), or 'l' (large) - sets hidden_size, num_heads, time_depth, vit_model
  track_type: '2d'               # '2d' or '3d' - must match dataset_config.yaml
  hand_mode: null                # 'left', 'right', 'both', or null - must match dataset_config.yaml
  text_mode: false               # Enable text/language conditioning
  # Note: num_future_steps, frame_stack are derived from dataset_config
  model_resolution: [256, 256]
  add_space_attn: true
  vit_frozen: false              # Fine-tune ViT (when unfreeze_after=0, this controls initial state)
  p_drop_attn: 0.1

# Training configuration
training:
  # Device configuration
  device: 'cuda'                # Device to use: 'cuda', 'cuda:0', 'cuda:1', 'cpu', etc.
  
  num_epochs: 150
  batch_size: 32
  num_workers: 4

  lr: 1.0e-4
  weight_decay: 1.0e-5
  grad_clip: 1.0

  use_amp: true
  use_compile: true
  ema_decay: 0.999
  
  # Encoder unfreezing schedule (curriculum learning for ViT + SigLIP)
  unfreeze_after: 0.0           # Unfreeze encoders at 30% of training (0.0 = always unfrozen)

  lr_schedule: "cosine"
  warmup_epochs: 5
  min_lr: 1.0e-6

  val_every_n_epochs: 5
  val_vis_samples: 64

  checkpoint_dir: "./checkpoints"

  wandb_project: "intent-tracker"
  wandb_entity: null
  log_every_n_steps: 10
  log_gradients: true
  log_params: true
