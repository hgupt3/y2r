# Adaptive Multi-GPU Dataset Processing - Test Report

**Date**: 2026-01-16
**System**: RTX 5090 (31.3GB), PyTorch 2.9.1+cu128
**Mode**: Adaptive worker spawning with 'spawn' multiprocessing context

---

## Executive Summary

Successfully implemented and tested adaptive multi-GPU worker infrastructure for the dataset processing pipeline. Fixed critical bugs including CUDA multiprocessing compatibility and worker deadlock issues. ViPE processing completed on 5 test videos.

---

## Issues Fixed

### 1. **PyTorch RTX 5090 Compatibility** âœ…
- **Problem**: PyTorch 2.7.0+cu124 missing sm_120 (Blackwell) kernel support
- **Solution**: Upgraded to PyTorch 2.9.1+cu128
- **Result**: Full CUDA support on RTX 5090

### 2. **Missing Dependencies** âœ…
- **Problem**: MoGe package required by ViPE not installed
- **Solution**: `pip install git+https://github.com/microsoft/MoGe.git`
- **Result**: ViPE model loading works

### 3. **Adaptive Worker Deadlock** âœ…
- **Problem**: Workers waiting for stop signal, main process waiting for 'finished' messages
- **Solution**: Added explicit 'stop' messages to work queue after all items
- **Code**: `dataset_scripts/utils/adaptive_workers.py` lines 115-117, 346-348
- **Result**: Workers cleanly exit after processing

### 4. **CUDA Multiprocessing Error** âœ…
- **Problem**: `"Cannot re-initialize CUDA in forked subprocess"`
- **Root Cause**: Default 'fork' context incompatible with CUDA
- **Solution**: Changed to 'spawn' context (`mp.get_context('spawn')`)
- **Code**: `dataset_scripts/utils/adaptive_workers.py` line 18
- **Result**: Workers spawn successfully without CUDA errors

---

## Test Results

### ViPE (Depth Estimation)

**Configuration**:
- Max workers per GPU: 1 (limited due to memory)
- Spawn delay: 30 seconds
- Test videos: 5

**Run 1** (max_workers=4):
- Workers spawned: 2 (Worker 2 OOMed during model load)
- Videos processed: 2/5 (00000, 00001)
- Failures: 3 videos OOMed during processing
- **Finding**: 2 workers can load (~26GB), but not enough headroom for inference

**Run 2** (max_workers=1):
- Workers spawned: 1 âœ…
- Videos processed: 5/5 âœ…
- Failures: 0
- **Result**: SUCCESS with 1 worker

**Memory Profile**:
- Model load: ~13GB per worker
- Video processing: +1-4GB peak during inference
- Total per worker: ~14-17GB
- **Optimal**: 1 worker for RTX 5090 (31GB)

**Output**:
```
/home/harsh/y2r/data/vipe/
â”œâ”€â”€ 00000.npz (20MB)
â”œâ”€â”€ 00001.npz (19MB)
â”œâ”€â”€ 00002.npz (9.7MB)
â”œâ”€â”€ 00003.npz (29MB)
â””â”€â”€ 00004.npz (14MB)
```

---

## Architecture Changes

### File: `dataset_scripts/utils/adaptive_workers.py`

**Lines 8-18**: Use spawn context for CUDA
```python
import multiprocessing as mp
# ...
mp_ctx = mp.get_context('spawn')
```

**Lines 68-70**: Create queues with spawn context
```python
self.work_queue = mp_ctx.Queue()
self.result_queue = mp_ctx.Queue()
self.stop_event = mp_ctx.Event()
```

**Lines 115-117**: Send stop messages
```python
for _ in range(self.max_stable_workers):
    self.work_queue.put(('stop', None))
```

**Lines 169-180**: Use spawn context for Process
```python
worker = mp_ctx.Process(
    target=_worker_main,
    args=(...),
    daemon=True,
)
```

**Lines 346-348**: Handle stop message
```python
if msg_type == 'stop':
    break
```

### File: `dataset_scripts/process_vipe.py`

**Line 665**: Increased spawn delay for ViPE
```python
spawn_delay=30.0,  # ViPE models are heavy
```

**Lines 494-544**: Fixed ViPEWorkerFunction
- Moved model loading to `load_model()` method
- Uses actual ViPE functions instead of missing imports

---

## Current Status

### âœ… Completed
- [x] GPU detection working (RTX 5090 detected)
- [x] Adaptive worker pool spawning
- [x] ViPE processing 5 videos successfully
- [x] All critical bugs fixed

### ðŸ”„ In Progress
- [ ] Testing TAPIP3D (running now)
- [ ] Testing WiLoR
- [ ] Testing create_h5_dataset
- [ ] Full pipeline verification

### ðŸ“‹ Pending
- [ ] Implement smart memory-aware worker detection
- [ ] Run full dataset (55 videos)
- [ ] Performance benchmarking
- [ ] Multi-GPU testing (when A100 cluster available)

---

## Lessons Learned

### What Worked
1. **Spawn context is essential** for CUDA multiprocessing
2. **Conservative worker counts** (1 worker) ensure reliability
3. **Background task monitoring** allows parallel development

### What Needs Improvement
1. **Spawn-until-OOM is naive** - should monitor actual memory usage
2. **30s spawn delay** is arbitrary - could be adaptive
3. **No retry mechanism** for failed videos
4. **Memory headroom unclear** - need better profiling

### Proposed Improvements
1. **Memory-aware spawning**:
   - Spawn 1 worker
   - Process 1-2 videos, monitor peak GPU memory
   - Calculate: `optimal = floor(total_mem / peak_mem * 0.9)`
   - Spawn remaining workers in one go

2. **Adaptive spawn delay**:
   - Start with 5s delay
   - If worker dies, double delay (exponential backoff)
   - If worker succeeds, reduce delay

3. **Graceful degradation**:
   - If worker OOMs during processing, free memory and retry
   - Track per-video memory requirements
   - Skip videos that consistently OOM

---

## Next Steps

1. **Complete pipeline testing** on 5 videos (TAPIP3D â†’ WiLoR â†’ H5)
2. **Verify output quality** (validate .npz files, check trajectories)
3. **Design memory-aware spawning** (implement smart worker detection)
4. **Test on full dataset** (55 videos) if pipeline validates
5. **Prepare for A100 cluster** (multi-GPU support already implemented)

---

## Performance Notes

**ViPE Timing** (5 videos, 1 worker):
- Total time: ~3-4 minutes
- Average: ~40-50s per video
- Model loading: ~22s (one-time)

**Expected Full Dataset** (55 videos, 1 worker):
- Estimated: ~7-9 minutes for ViPE
- With 2-3 workers: ~3-4 minutes
- On A100 cluster (8 GPUs): <1 minute potentially

---

## Configuration

**Current settings** (`dataset_scripts/config.yaml`):
```yaml
optimization:
  use_adaptive_workers: true
  max_workers_per_gpu: 1  # Conservative for ViPE
  gpu_strategy: 'round-robin'
  spawn_delay: 30.0  # For heavy models like ViPE
```

**Recommended for production**:
- ViPE: 1-2 workers (monitor memory)
- TAPIP3D: TBD (testing now)
- WiLoR: TBD (testing next)
- create_h5: CPU-bound, try 4-8 workers

---

_Report auto-generated during testing session_
